{
  "filename": "Project 1 - LLM_P4_Network_Security_Pitch.pptx",
  "text": "Utilizing LLMs to Enhance P4 Programming for Networking Security\nProject Pitch\nComputer Security Course - Spring 2025\nMotivation\n- P4 is a powerful language for programmable networks but requires expertise.\n- Large Language Models (LLMs) like ChatGPT, Gemini, Claude, and DeepSeek can assist in writing P4 code.\n- Enhancing security strategies in networking through AI-guided programming.\n- Need to defend against evolving cyber threats in real-time network environments.\nProject Objectives\n- Utilize multiple LLMs to assist students in writing and optimizing P4 code.\n- Develop AI-enhanced security policies for network protection.\n- Test security strategies against various cyberattack models.\n- Validate results using Mininet or real-world experimental testbeds.\nMethodology\n1. Select multiple LLMs (ChatGPT, Gemini, Claude, DeepSeek) for comparison.\n2. Use LLMs to generate P4-based networking security strategies.\n3. Simulate and deploy these strategies in Mininet or real-world testbeds.\n4. Conduct security assessments against various cyberattacks (e.g., DDoS, Man-in-the-Middle, Packet Injection).\n5. Evaluate effectiveness based on attack mitigation performance and efficiency.\nCyberattack Models to Evaluate\n- DDoS (Distributed Denial of Service)\n- Man-in-the-Middle (MITM) Attacks\n- Packet Injection Attacks\n- TCP/IP Spoofing\n- ARP Poisoning\n- Custom Attack Models Defined by your team\nValidation Strategy\n- Option 1: Mininet-based simulation for cost-effective testing.\n- Option 2: Real-world experimental testbed for high-fidelity results.\n- Compare LLM-generated P4 policies with manually designed ones.\n- Measure metrics: attack mitigation success rate, network performance impact, and efficiency of LLM-generated code.\nExpected Outcomes\n- Demonstrate how LLMs can enhance P4 programming efficiency.\n- Develop robust AI-assisted security strategies for networks.\n- Evaluate LLM performance across multiple cyberattack scenarios.\n- Provide insights into the strengths and limitations of LLMs in cybersecurity applications.\nProject Timeline â€“ an example\nWeek 1-2: Familiarization with P4 programming and LLMs.\nWeek 3-4: Develop initial LLM-assisted P4 code.\nWeek 5-6: Test P4 security strategies in Mininet.\nWeek 7-8: Evaluate performance against cyberattack models.\nWeek 9-10: Final adjustments and analysis.\nWeek 11: Presentation and report submission.\nProject mentor and their expertise\nKevin Kostage: Can help generating real-world Testbed environment using Fabric and Chameleon, with L3 and L2 connections. \n\n\nSean Peppers: Have plenty of experiences on running P4 and knows P4 basic settings. Can help with initialization LLM prompt generation.\n"
}